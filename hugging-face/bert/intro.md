GPT models are great at generating text, images, audio in response to a prompt
It is why they are called generative to begin.

However, Natural language processing isn't just limited to generative tasks. 
It is why GPT models aren't the only large language models out there. 
For example, there is the BERT model

## BERT - Bidirectional Encoder Representations Tranformers
Like GPT, it is pretrained and uses the transformer architecture
While GPT models essentially predict the next word in a sequence(autoregressive)
BERT predicts missing word by analysing the context in both directions
GPT models are great for - conversations, chatbots
BERT models are great for sentiment analysis, NER, question-answering